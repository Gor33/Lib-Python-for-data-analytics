# Вам необходимо написать функцию, которая будет основана на поиске по сайту habr.com. Функция в качестве параметра должна принимать список запросов для поиска (например, ['python', 'анализ данных']) и на основе материалов, 
# попавших в результаты поиска по каждому запросу, возвращать датафрейм вида:
# <дата> - <заголовок> - <ссылка на материал>
# В рамках задания предполагается работа только с одной (первой) страницей результатов поисковой выдачи для каждого запроса. Материалы в датафрейме не должны дублироваться, если они попадали в результаты поиска для нескольких запросов из списка.

import requests
import time
import pandas as pd
from bs4 import BeautifulSoup
pages = 1

keywords = ['скраппинг', 'парсинг', 'программирование', 'разработка']

def scrap_habr_by_word(key_word):
    URL = f'https://habr.com/ru/search/?q={key_word}&target_type=posts&order=relevance'
    req = requests.get(URL)
    time.sleep(0.3)
    soup = BeautifulSoup(req.text, features="html.parser")
    news_blocks = soup.find_all('article', class_='tm-articles-list__item')
    headers = []
    links = []
    dts = []
    
    for e in news_blocks:
        dts.append(e.find('time').get_text())
        el = e.find(class_='tm-title__link')
        headers.append(el.find('span').get_text())
        links.append(f"https://habr.com/{el['href']}")
    data = {'date': dts, 'header': headers, 'link': links} 
    return pd.DataFrame(data)


def scrap_habr(keywords):
    data = pd.DataFrame({'date': [], 'header': [], 'link': []})
    for key in keywords:
        data = pd.concat([data, scrap_habr_by_word(key)])
    return data.drop_duplicates()
df = scrap_habr(keywords)
print(df)

